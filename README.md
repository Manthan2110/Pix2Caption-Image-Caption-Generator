# ğŸ–¼ï¸ Pix2Caption â€“ AI Image Caption Generator  
*â€œLet AI describe what it sees.â€* ğŸ¤–ğŸ“  
Pix2Caption is an **image-to-text** application that analyzes a photo and generates a natural-language caption in real time. Built with ğŸ§  TensorFlow/Keras and ğŸ¨ Streamlit, it showcases the fusion of **Computer Vision** and **Natural Language Processing**.

---

## ğŸ§  Problem Statement  
Manually describing large numbers of images is tedious and inconsistent.  
> â“ *â€œCan we automatically create meaningful captions for any image?â€*  
> âœ… *Yesâ€”Pix2Caption proves it with a deep learning encoderâ€“decoder model.*

---

## ğŸŒ Live Demo  
Visit the deployed Streamlit app to upload any image and get an instant AI-generated caption.


https://pix2caption-image-captioning.streamlit.app/

---

## ğŸ“¦ Features  
- ğŸ“¤ **Image Upload** â€“ Supports JPG, JPEG, PNG  
- ğŸ§  **Deep Learning Model** â€“ DenseNet-201 CNN encoder + LSTM decoder  
- ğŸ”¤ **Tokenizer & Sequence Handling** â€“ Start/End tokens, padded sequences  
- âš¡ **Real-Time Inference** â€“ Generates captions on-the-fly  
- ğŸ’¾ **Download** â€“ Save generated captions as `.txt` files  
- ğŸ¨ **Responsive UI** â€“ Modern Streamlit interface with custom CSS

---

## ğŸ—ï¸ Architecture  

```text
User Image â¡ï¸ Feature Extractor (DenseNet-201 CNN)
             â¡ï¸ LSTM Decoder with Tokenizer
             â¡ï¸ Word-by-word Caption Generation
```
---

## Project files
| File/Folder                      | Description                                            |
| -------------------------------- | ------------------------------------------------------ |
| `Pix2Caption.ipynb`              | Model training, preprocessing, and evaluation notebook |
| `main.py`                        | Streamlit frontend for deployment                      |
| `models/caption_model.keras`     | Trained LSTM decoder                                   |
| `models/feature_extractor.keras` | CNN encoder for image feature extraction               |
| `models/tokenizer.pkl`           | Saved tokenizer vocabulary                             |
| `requirements.txt`               | Python dependencies                                    |


--- 
## ğŸ” Technologies Used

- ğŸ§  TensorFlow / Keras â€“ Model building & training

- ğŸ–¼ï¸ DenseNet-201 â€“ Pretrained CNN encoder

- ğŸ” LSTM â€“ Text sequence decoder

- ğŸ“¦ Streamlit â€“ Interactive web UI

- ğŸ Python â€“ NumPy, Pillow, Pickle, etc.
---

## ğŸš€ Installation & Setup
1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/Manthan2110/Pix2Caption.git
cd Pix2Caption
```

2ï¸âƒ£ Create and activate a virtual environment
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

4ï¸âƒ£ Run the Streamlit app
```bash
streamlit run main.py
```

---

## ğŸ“ˆ How It Works

Upload an image from your device.

Encoder (DenseNet-201) extracts visual feature vectors.

Decoder (LSTM) predicts the next word step-by-step until the <end> token.

The generated caption is displayed and available for download.

---

## Future Enchantment
| Feature                         | Description                                      |
| ------------------------------- | ------------------------------------------------ |
| ğŸ” Attention Mechanism          | Improve caption relevance with spatial attention |
| ğŸŒ Multi-language Support       | Generate captions in different languages         |
| ğŸ§  Transformer Decoder          | Upgrade to a Transformer for richer descriptions |
| ğŸŒŒ Beam Search / Top-k Sampling | Produce more diverse, higher-quality captions    |
| ğŸ“Š Evaluation Metrics           | Integrate BLEU, METEOR, CIDEr scoring            |

---
## ğŸ‘¨â€ğŸ’» Author

Made with â¤ï¸ by Manthan Jadav

--- 
## ğŸ“œ License

This project is licensed under the MIT License.
Feel free to fork, modify, and share!
